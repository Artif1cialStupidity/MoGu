# generate randomly initialized surrogate model
python defenses/victim/train.py CIFAR100 vgg16_bn --out_path models/victim/CIFAR100-vgg16_bn-train-nodefense-scratch-advproxy --device_id 0 --epochs 1 --train_subset 10 --lr 0.0

################################ CIFAR-100 ################################
### If you have multiple GPUs on the machine, use this to select the specific GPU
dev_id=3
### p_v = victim model dataset
p_v=CIFAR100
### f_v = architecture of victim model
f_v=vgg16_bn
### queryset = p_a = image pool of the attacker 
queryset=TinyImageNet200
### Path to victim model's directory (the one downloded earlier)
vic_dir=models/victim/${p_v}-${f_v}-train-nodefense
### No. of images queried by the attacker. With 60k, attacker obtains 99.05% test accuracy on MNIST at eps=0.0.
budget=50000 
### Batch size of queries to process for the attacker
batch_size=32
### Training parameters
lr=0.1
lr_step=10
lr_gamma=0.5
epochs=30
training_batch_size=128

### attack policy
## pretrained model
# use imagenet pretrained
pretrained=imagenet

# use optimal pretrained
pretrained=${vic_dir}

### attack policy
## random
policy=random
hardlabel=0
defense_aware=1

# Lookup Table Attack
recover_table_size=1000000
recover_norm=1
recover_tolerance=0.01
concentration_factor=8.0
recover_proc=5
policy_suffix="_da${defense_aware}_hard${hardlabel}"
recover_params="table_size:${recover_table_size};recover_norm:${recover_norm};tolerance:${recover_tolerance};concentration_factor:${concentration_factor};recover_proc:${recover_proc}"


# D-DAE Attack
recover_table_size=1000000
concentration_factor=8.0
recover_proc=10
policy_suffix="_ddae${defense_aware}_hard${hardlabel}"
recover_params="table_size:${recover_table_size};concentration_factor:${concentration_factor};recover_proc:${recover_proc};recover_nn:1"


## jbda/jbself/jbtop
policy=jbtop3
seedsize=500
jb_epsilon=0.1
T=8
policy_suffix="ss${seedsize}_eps${jb_epsilon}"

## semisupervised setting
semi_train_weight=0.0
semi_dataset=${queryset}

### Defense strategy
## Quantization
quantize=0
quantize_epsilon=0.0
optim=0
ydist=l1

# get centroids from query
frozen=0
quantize_args="epsilon:${quantize_epsilon};ydist:${ydist};optim:${optim};frozen:${frozen};ordered_quantization:1"

# get centroids with trainning set
frozen=1
quantize_args="epsilon:${quantize_epsilon};ydist:${ydist};optim:${optim};trainingset_name:${p_v};frozen:${frozen};buffer_size:20000"

## None
strat=none
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/none/quantize${quantize_epsilon}
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="out_path:${out_dir}"

## MAD
strat=mad
# Metric for perturbation ball dist(y, y'). Supported = L1, L2, KL
ydist=l1
# Perturbation norm
eps=1.0

# version 1: original MAD
batch_size=1
# Perturbation mode: extreme|argmax
oracle=argmax
# Initialization to the defender's surrogate model. 'scratch' refers to random initialization.
proxystate=scratch
# Path to surrogate model
proxydir=models/victim/${p_v}-${f_v}-train-nodefense-${proxystate}-advproxy
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/mad_${oracle}_${ydist}/eps[${eps},${quantize_epsilon}]-proxy_${proxystate}
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="epsilon:${eps};batch_constraint:0;objmax:1;oracle:${oracle};ydist:${ydist};model_adv_proxy:${proxydir};out_path:${out_dir}"

# version 2: LP-based MAD
# Perturbation mode: lp_extreme|lp_argmax
oracle=lp_argmax
# Using Batch Constraint
batch_constraint=0
# Initialization to the defender's surrogate model. 'scratch' refers to random initialization.
proxystate=scratch
# Path to surrogate model
proxydir=models/victim/${p_v}-${f_v}-train-nodefense-${proxystate}-advproxy
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/mad_${oracle}_${ydist}/batch${batch_size}-eps[${eps},${quantize_epsilon}]_bc${batch_constraint}-proxy_${proxystate}
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="epsilon:${eps};batch_constraint:${batch_constraint};objmax:1;oracle:${oracle};ydist:${ydist};model_adv_proxy:${proxydir};out_path:${out_dir}"

# Version 3: MUAD (Use I as jacobian in MAD)
# Perturbation mode: lp_extreme|lp_argmax
oracle=lp_argmax
# Using Batch Constraint
batch_constraint=0
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/muad_${oracle}_${ydist}/batch${batch_size}-eps[${eps},${quantize_epsilon}]_bc${batch_constraint}
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="epsilon:${eps};batch_constraint:${batch_constraint};objmax:1;oracle:${oracle};ydist:${ydist};disable_jacobian:1;out_path:${out_dir}"

## MLD
strat=mld
# Using Batch Constraint
batch_constraint=0
# Metric for perturbation ball dist(y, y'). Supported = L1, L2, KL
ydist=l1
# Perturbation norm
eps=1.0
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/mld_${ydist}/batch${batch_size}-eps[${eps},${quantize_epsilon}]_bc${batch_constraint}
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="epsilon:${eps};batch_constraint:${batch_constraint};ydist:${ydist};out_path:${out_dir}"

## random noise
strat=rand_noise
# Metric for perturbation ball dist(y, y'). Supported = L1, L2, KL
zdist=l1
# Perturbation norm
eps=10.0
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/rand_${zdist}/eps[${eps},${quantize_epsilon}]
# Parameters to defense strategy, provided as a key:value pair string. 
defense_args="epsilon_z:${eps};dist_z:${zdist};out_path:${out_dir}"

## topk
strat=topk
topk=1
rounding=0
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/top${topk}-rounding${rounding}
defense_args="topk:${topk};rounding:${rounding};out_path:${out_dir}"

## rounding
strat=rounding
rounding=1
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/rounding${rounding}
defense_args="rounding:${rounding};out_path:${out_dir}"

## reverse sigmoid
strat=reverse_sigmoid
beta=0.02
gamma=0.2
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/revsig/beta${beta}-gamma${gamma}-quantize${quantize_epsilon}
defense_args="beta:${beta};gamma:${gamma};out_path:${out_dir}"

## Adaptive Misinformation
strat=am
oe_lamb=1.0
oeset=SVHN
defense_lv=0.99
# Output path to attacker's model
out_dir=models/final_bb_dist/${p_v}-${f_v}/${policy}${policy_suffix}-${queryset}-B${budget}/am/tau${defense_lv}-quantize${quantize_epsilon}
defense_args="defense_level:${defense_lv};out_path:${out_dir}"

### Execution commands
# (defense) train an original (blackbox) model
python defenses/victim/train.py ${p_v} ${f_v} -o ${vic_dir} -b 64 -d ${dev_id} -e 100 -w 4 --lr 0.01 --lr_step 30 --lr_gamma 0.5 --pretrained ${pretrained}

# (defense) AM training
python defenses/victim/train_admis.py ${p_v} ${f_v} -o ${vic_dir} -b 64 -d ${dev_id} -e 100 -w 4 --lr 0.01 --lr_step 30 --lr_gamma 0.5 --pretrained ${pretrained} --oe_lamb ${oe_lamb} -doe ${oeset}

# (defense) evaluate original model with defense on testset
python defenses/victim/eval.py ${vic_dir} ${strat} ${defense_args} --out_dir ${out_dir} --batch_size ${batch_size} -d ${dev_id}

# (adversary) generate transfer dataset (only when policy=random)
python defenses/adversary/transfer.py ${policy} ${vic_dir} ${strat} ${defense_args} --out_dir ${out_dir} --batch_size ${batch_size} -d ${dev_id} --queryset ${queryset} --budget ${budget} --quantize ${quantize} --quantize_args ${quantize_args} --defense_aware ${defense_aware} --recover_args ${recover_params} --hardlabel ${hardlabel}

# (adversary) train kickoffnet and evaluate
python defenses/adversary/train.py ${out_dir} ${f_v} ${p_v} --budgets 50000 -e ${epochs} -b ${training_batch_size} --lr ${lr} --lr_step ${lr_step} --lr_gamma ${lr_gamma} -d ${dev_id} -w 4 --pretrained ${pretrained} --vic_dir ${vic_dir} --semitrainweight ${semi_train_weight} --semidataset ${semi_dataset} 

# (adversary) use jbda/jbda-topk as attack policy
python defenses/adversary/jacobian.py ${policy} ${vic_dir} ${strat} ${defense_args} --model_adv ${f_v} --pretrained imagenet --out_dir ${out_dir} --testset ${p_v} --batch_size 128 -d ${dev_id} --queryset ${queryset} --budget ${budget} --seedsize ${seedsize} --epsilon ${jb_epsilon} --T ${T} --train_epochs 20